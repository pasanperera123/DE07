# Automated Serverless Web Scraping ETL Pipeline with GitHub Actions




The final solution is a fully automated, serverless ETL pipeline that performs daily web scraping, data transformation, and cloud storage — all without any human intervention. It’s scalable, cost-efficient, and demonstrates the power of combining AWS serverless services, Python-based automation, and DevOps practices in a real-world project.

To streamline deployment, I integrated GitHub Actions for continuous integration and continuous deployment (CI/CD). The workflow automatically builds and pushes the Docker image to AWS whenever changes are committed to the main branch, eliminating the need for manual updates and improving deployment reliability.


Detailed summary : https://medium.com/@pasan.eecs/automated-serverless-web-scraping-etl-pipeline-with-github-actions-25ffbbad6a10
